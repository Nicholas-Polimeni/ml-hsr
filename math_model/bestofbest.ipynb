{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fdurrani/.pyenv/versions/3.9.17/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fdurrani/.pyenv/versions/3.9.17/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fdurrani/.pyenv/versions/3.9.17/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/fdurrani/.pyenv/versions/3.9.17/lib/python3.9/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'get_most_viable_data' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 218\u001b[0m\n\u001b[1;32m    214\u001b[0m     best_of_best \u001b[38;5;241m=\u001b[39m max_viable_cities_df\u001b[38;5;241m.\u001b[39mhead(top_n)\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_of_best\n\u001b[0;32m--> 218\u001b[0m bb \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_of_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m bb\n",
      "Cell \u001b[0;32mIn[2], line 194\u001b[0m, in \u001b[0;36mget_best_of_best\u001b[0;34m(dataset, top_n)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_of_best\u001b[39m(dataset, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m--> 194\u001b[0m     max_viable_cities \u001b[38;5;241m=\u001b[39m \u001b[43mget_most_viable_for_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     max_viable_cities_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m city_source \u001b[38;5;129;01min\u001b[39;00m max_viable_cities:\n",
      "Cell \u001b[0;32mIn[2], line 187\u001b[0m, in \u001b[0;36mget_most_viable_for_all\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    185\u001b[0m max_viable_cities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool() \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m--> 187\u001b[0m     max_viable_cities \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_most_viable_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# for _, city_item in tqdm(dataset.iterrows(), total=len(dataset)):\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m#     max_viable_cities.append(get_most_viable_data(city_item))\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_viable_cities\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from colour import Color\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydeck as pdk\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# import streamlit as st\n",
    "\n",
    "GEONAME_ID = \"metro\"\n",
    "NAME = \"metro\"\n",
    "POPULATION = \"population\"\n",
    "COU_NAME_EN = \"country_code\"\n",
    "LATITUDE = \"latitude\"\n",
    "LONGITUDE = \"longitude\"\n",
    "DATASET_CSV_PATH = \"../data/metro_regions.csv\"\n",
    "\n",
    "\n",
    "def get_dataset(csv_name):\n",
    "    dataset = pd.read_csv(csv_name)\n",
    "    dataset = dataset.drop_duplicates()\n",
    "\n",
    "    # pick columns to use\n",
    "    columns = [\n",
    "        # GEONAME_ID,\n",
    "        NAME,\n",
    "        POPULATION,\n",
    "        COU_NAME_EN,\n",
    "        LATITUDE,\n",
    "        LONGITUDE,\n",
    "    ]\n",
    "    dataset = dataset[columns]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dist(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of the earth in km\n",
    "    dLat = np.deg2rad(lat2 - lat1)\n",
    "    dLon = np.deg2rad(lon2 - lon1)\n",
    "    a = np.sin(dLat / 2) * np.sin(dLat / 2) + np.cos(np.deg2rad(lat1)) * np.cos(\n",
    "        np.deg2rad(lat2)\n",
    "    ) * np.sin(dLon / 2) * np.sin(dLon / 2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    d = R * c  # Distance in km\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_max_dist(dataset_item, dataset):\n",
    "    lat1 = dataset_item[LATITUDE]\n",
    "    lon1 = dataset_item[LONGITUDE]\n",
    "    city_max_dist = 0\n",
    "    for _, row in dataset.iterrows():\n",
    "        lat2 = row[LATITUDE]\n",
    "        lon2 = row[LONGITUDE]\n",
    "        dist = get_dist(lat1, lon1, lat2, lon2)\n",
    "        if dist > city_max_dist:\n",
    "            city_max_dist = dist\n",
    "    return city_max_dist\n",
    "\n",
    "\n",
    "def get_city_item(name_or_id, dataset):\n",
    "    def get_city_with_max_pop(subset):\n",
    "        return subset[subset[POPULATION] == subset[POPULATION].max()].iloc[0]\n",
    "\n",
    "    if isinstance(name_or_id, int):\n",
    "        subset = dataset[dataset[GEONAME_ID] == name_or_id]\n",
    "    else:\n",
    "        subset = dataset[dataset[NAME].str.contains(name_or_id) == True]\n",
    "    if len(subset) == 0:\n",
    "        raise Exception(f\"City {name_or_id} not found\")\n",
    "    return get_city_with_max_pop(subset)\n",
    "\n",
    "\n",
    "def get_viability(city_1, city_2, dataset, dataset_statistics, A=1, B=1, verbose=False):\n",
    "    min_pop, max_pop, avg_pop, min_dist, max_dist = (\n",
    "        dataset_statistics[\"min_pop\"],\n",
    "        dataset_statistics[\"max_pop\"],\n",
    "        dataset_statistics[\"avg_pop\"],\n",
    "        dataset_statistics[\"min_dist\"],\n",
    "        dataset_statistics[\"max_dist\"],\n",
    "    )\n",
    "    pop_1 = city_1[POPULATION]\n",
    "    pop_2 = city_2[POPULATION]\n",
    "    sum_pop = pop_1 + pop_2\n",
    "    dist = get_dist(\n",
    "        city_1[LATITUDE], city_1[LONGITUDE], city_2[LATITUDE], city_2[LONGITUDE]\n",
    "    )\n",
    "    normalized_pop = (sum_pop - min_pop) / (max_pop + avg_pop - min_pop)\n",
    "    normalized_dist = (dist - min_dist) / (max_dist - min_dist)\n",
    "    if verbose:\n",
    "        print(sum_pop, normalized_pop, dist, normalized_dist)\n",
    "    return A * normalized_pop - B * normalized_dist\n",
    "\n",
    "\n",
    "def find_most_viable_city(city_name, dataset):\n",
    "    city = get_city_item(city_name, dataset)\n",
    "    max_viability = 0\n",
    "    max_viable_city = None\n",
    "    for _, row in dataset.iterrows():\n",
    "        if row[GEONAME_ID] != city[GEONAME_ID]:\n",
    "            viability = get_viability(city, row, dataset)\n",
    "            if viability > max_viability:\n",
    "                max_viability = viability\n",
    "                max_viable_city = row\n",
    "    return max_viable_city\n",
    "\n",
    "\n",
    "def find_top_viable_cities(city_name, dataset, dataset_statistics, top_n=5, A=1, B=1):\n",
    "    city = get_city_item(city_name, dataset)\n",
    "    viabilities = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        if row[GEONAME_ID] != city[GEONAME_ID]:\n",
    "            viability = get_viability(city, row, dataset, dataset_statistics, A, B)\n",
    "            viabilities.append((viability, row))\n",
    "    viabilities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return viabilities[:top_n]\n",
    "\n",
    "\n",
    "def get_viable_cities_paths(\n",
    "    city_1_name, dataset, dataset_statistics, top_n=5, A=1, B=1\n",
    "):\n",
    "    city_1 = get_city_item(city_1_name, dataset)\n",
    "    most_viable_cities = find_top_viable_cities(\n",
    "        city_1_name, dataset, dataset_statistics, top_n, A, B\n",
    "    )\n",
    "    paths_dict = []\n",
    "    for city in most_viable_cities:\n",
    "        city_2 = city[1]\n",
    "        paths_dict.append(\n",
    "            {\n",
    "                \"path\": [\n",
    "                    [city_1[LONGITUDE], city_1[LATITUDE]],\n",
    "                    [city_2[LONGITUDE], city_2[LATITUDE]],\n",
    "                ],\n",
    "                \"viability\": f\"{city[0] * 100}%\",\n",
    "                \"city_2\": city_2[NAME],\n",
    "            }\n",
    "        )\n",
    "    red = Color(\"red\")\n",
    "    colors = list(red.range_to(Color(\"green\"), len(paths_dict)))\n",
    "    for i, path in enumerate(paths_dict):\n",
    "        path[\"color\"] = colors[i].hex_l\n",
    "    return pd.DataFrame(paths_dict)\n",
    "\n",
    "\n",
    "dataset = get_dataset(DATASET_CSV_PATH)\n",
    "\n",
    "# remove empty rows\n",
    "dataset = dataset.dropna()\n",
    "print(len(dataset))\n",
    "\n",
    "# dataset = dataset[dataset[COU_NAME_EN] == \"United States\"]\n",
    "dataset_statistics = {\n",
    "    \"min_pop\": dataset[POPULATION].min(),\n",
    "    \"max_pop\": dataset[POPULATION].max(),\n",
    "    \"avg_pop\": dataset[POPULATION].mean(),\n",
    "    \"min_dist\": 0,\n",
    "    \"max_dist\": get_max_dist(get_city_item(\"Atlanta\", dataset), dataset),\n",
    "}\n",
    "\n",
    "# Text box input\n",
    "user_city_input = \"Atlanta\"\n",
    "user_A_input = 1\n",
    "user_B_input = 1\n",
    "df1 = get_viable_cities_paths(\n",
    "    user_city_input,\n",
    "    dataset,\n",
    "    dataset_statistics,\n",
    "    5,\n",
    "    A=float(user_A_input),\n",
    "    B=float(user_B_input),\n",
    ")\n",
    "\n",
    "\n",
    "def get_most_viable_data(city_item):\n",
    "    city = city_item\n",
    "    max_viable_cities = find_top_viable_cities(\n",
    "        city[NAME], dataset, dataset_statistics=dataset_statistics\n",
    "    )\n",
    "    return {\"source\": city, \"max_viable_cities\": max_viable_cities}\n",
    "\n",
    "\n",
    "def get_most_viable_for_all(dataset):\n",
    "    max_viable_cities = []\n",
    "    with Pool() as p:\n",
    "        max_viable_cities = p.map(get_most_viable_data, dataset)\n",
    "    # for _, city_item in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "    #     max_viable_cities.append(get_most_viable_data(city_item))\n",
    "    return max_viable_cities\n",
    "\n",
    "\n",
    "def get_best_of_best(dataset, top_n=5):\n",
    "    max_viable_cities = get_most_viable_for_all(dataset)\n",
    "    max_viable_cities_list = []\n",
    "    for city_source in max_viable_cities:\n",
    "        city_source_item = city_source[\"source\"]\n",
    "        for viable_city in city_source[\"max_viable_cities\"]:\n",
    "            max_viable_cities_list.append(\n",
    "                {\n",
    "                    \"source\": city_source_item[NAME],\n",
    "                    \"source_lat\": city_source_item[LATITUDE],\n",
    "                    \"source_lon\": city_source_item[LONGITUDE],\n",
    "                    \"destination\": viable_city[1][NAME],\n",
    "                    \"destination_lat\": viable_city[1][LATITUDE],\n",
    "                    \"destination_lon\": viable_city[1][LONGITUDE],\n",
    "                    \"viability\": viable_city[0],\n",
    "                }\n",
    "            )\n",
    "    max_viable_cities_df = pd.DataFrame(max_viable_cities_list)\n",
    "    max_viable_cities_df = max_viable_cities_df.sort_values(\n",
    "        by=[\"viability\"], ascending=False\n",
    "    )\n",
    "    best_of_best = max_viable_cities_df.head(top_n)\n",
    "    return best_of_best\n",
    "\n",
    "\n",
    "bb = get_best_of_best(dataset, 5)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
