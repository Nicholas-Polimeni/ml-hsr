{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1198],\n",
      "        [-0.3814],\n",
      "        [-0.1436],\n",
      "        [-0.4723]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[-0.0756],\n",
      "        [-0.2962],\n",
      "        [-0.0441],\n",
      "        [-0.3124]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[-0.0274],\n",
      "        [-0.2129],\n",
      "        [ 0.0543],\n",
      "        [-0.1532]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[ 0.0209],\n",
      "        [-0.1315],\n",
      "        [ 0.1524],\n",
      "        [ 0.0045]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[ 0.0688],\n",
      "        [-0.0520],\n",
      "        [ 0.2493],\n",
      "        [ 0.1601]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1157],\n",
      "        [0.0254],\n",
      "        [0.3448],\n",
      "        [0.3137]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1599],\n",
      "        [0.0993],\n",
      "        [0.4388],\n",
      "        [0.4648]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1994],\n",
      "        [0.1718],\n",
      "        [0.5312],\n",
      "        [0.6134]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2318],\n",
      "        [0.2438],\n",
      "        [0.6215],\n",
      "        [0.7591]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2571],\n",
      "        [0.3137],\n",
      "        [0.7093],\n",
      "        [0.9015]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [10/100], Loss: 0.3816\n",
      "tensor([[0.2765],\n",
      "        [0.3828],\n",
      "        [0.7939],\n",
      "        [1.0413]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2908],\n",
      "        [0.4502],\n",
      "        [0.8747],\n",
      "        [1.1766]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3007],\n",
      "        [0.5152],\n",
      "        [0.9504],\n",
      "        [1.3052]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3072],\n",
      "        [0.5773],\n",
      "        [1.0200],\n",
      "        [1.4250]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3111],\n",
      "        [0.6363],\n",
      "        [1.0827],\n",
      "        [1.5334]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3131],\n",
      "        [0.6916],\n",
      "        [1.1386],\n",
      "        [1.6281]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3133],\n",
      "        [0.7424],\n",
      "        [1.1848],\n",
      "        [1.7070]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3120],\n",
      "        [0.7878],\n",
      "        [1.2208],\n",
      "        [1.7689]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3092],\n",
      "        [0.8272],\n",
      "        [1.2474],\n",
      "        [1.8135]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.3050],\n",
      "        [0.8602],\n",
      "        [1.2646],\n",
      "        [1.8414]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [20/100], Loss: 0.2947\n",
      "tensor([[0.2993],\n",
      "        [0.8867],\n",
      "        [1.2733],\n",
      "        [1.8539]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2924],\n",
      "        [0.9072],\n",
      "        [1.2747],\n",
      "        [1.8528]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2843],\n",
      "        [0.9221],\n",
      "        [1.2700],\n",
      "        [1.8402]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2751],\n",
      "        [0.9326],\n",
      "        [1.2606],\n",
      "        [1.8185]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2652],\n",
      "        [0.9389],\n",
      "        [1.2479],\n",
      "        [1.7899]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2548],\n",
      "        [0.9417],\n",
      "        [1.2333],\n",
      "        [1.7564]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2442],\n",
      "        [0.9421],\n",
      "        [1.2179],\n",
      "        [1.7201]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2336],\n",
      "        [0.9409],\n",
      "        [1.2029],\n",
      "        [1.6827]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2234],\n",
      "        [0.9387],\n",
      "        [1.1891],\n",
      "        [1.6462]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2156],\n",
      "        [0.9364],\n",
      "        [1.1775],\n",
      "        [1.6124]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [30/100], Loss: 0.1197\n",
      "tensor([[0.2096],\n",
      "        [0.9343],\n",
      "        [1.1687],\n",
      "        [1.5811]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2049],\n",
      "        [0.9337],\n",
      "        [1.1633],\n",
      "        [1.5532]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2022],\n",
      "        [0.9347],\n",
      "        [1.1620],\n",
      "        [1.5293]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2014],\n",
      "        [0.9370],\n",
      "        [1.1644],\n",
      "        [1.5127]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2018],\n",
      "        [0.9406],\n",
      "        [1.1707],\n",
      "        [1.5014]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2033],\n",
      "        [0.9457],\n",
      "        [1.1810],\n",
      "        [1.4952]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2055],\n",
      "        [0.9524],\n",
      "        [1.1952],\n",
      "        [1.4941]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2082],\n",
      "        [0.9606],\n",
      "        [1.2131],\n",
      "        [1.4977]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2109],\n",
      "        [0.9703],\n",
      "        [1.2344],\n",
      "        [1.5061]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2134],\n",
      "        [0.9814],\n",
      "        [1.2590],\n",
      "        [1.5187]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [40/100], Loss: 0.0886\n",
      "tensor([[0.2151],\n",
      "        [0.9937],\n",
      "        [1.2866],\n",
      "        [1.5349]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2156],\n",
      "        [1.0069],\n",
      "        [1.3169],\n",
      "        [1.5542]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2147],\n",
      "        [1.0208],\n",
      "        [1.3492],\n",
      "        [1.5760]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2121],\n",
      "        [1.0355],\n",
      "        [1.3828],\n",
      "        [1.5996]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2079],\n",
      "        [1.0510],\n",
      "        [1.4171],\n",
      "        [1.6243]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.2020],\n",
      "        [1.0677],\n",
      "        [1.4512],\n",
      "        [1.6495]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1947],\n",
      "        [1.0855],\n",
      "        [1.4844],\n",
      "        [1.6743]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1861],\n",
      "        [1.1032],\n",
      "        [1.5162],\n",
      "        [1.6971]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1767],\n",
      "        [1.1204],\n",
      "        [1.5461],\n",
      "        [1.7170]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1669],\n",
      "        [1.1364],\n",
      "        [1.5735],\n",
      "        [1.7332]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [50/100], Loss: 0.0518\n",
      "tensor([[0.1571],\n",
      "        [1.1509],\n",
      "        [1.5979],\n",
      "        [1.7455]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1481],\n",
      "        [1.1638],\n",
      "        [1.6191],\n",
      "        [1.7536]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1404],\n",
      "        [1.1750],\n",
      "        [1.6372],\n",
      "        [1.7576]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1345],\n",
      "        [1.1846],\n",
      "        [1.6522],\n",
      "        [1.7580]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1324],\n",
      "        [1.1931],\n",
      "        [1.6645],\n",
      "        [1.7555]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1329],\n",
      "        [1.2018],\n",
      "        [1.6743],\n",
      "        [1.7520]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1354],\n",
      "        [1.2108],\n",
      "        [1.6821],\n",
      "        [1.7480]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1395],\n",
      "        [1.2202],\n",
      "        [1.6886],\n",
      "        [1.7444]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1447],\n",
      "        [1.2301],\n",
      "        [1.6946],\n",
      "        [1.7415]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1506],\n",
      "        [1.2404],\n",
      "        [1.7006],\n",
      "        [1.7399]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [60/100], Loss: 0.0356\n",
      "tensor([[0.1566],\n",
      "        [1.2512],\n",
      "        [1.7071],\n",
      "        [1.7402]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1618],\n",
      "        [1.2622],\n",
      "        [1.7146],\n",
      "        [1.7424]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1658],\n",
      "        [1.2737],\n",
      "        [1.7231],\n",
      "        [1.7470]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1684],\n",
      "        [1.2854],\n",
      "        [1.7328],\n",
      "        [1.7538]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1696],\n",
      "        [1.2967],\n",
      "        [1.7436],\n",
      "        [1.7624]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1695],\n",
      "        [1.3075],\n",
      "        [1.7554],\n",
      "        [1.7722]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1685],\n",
      "        [1.3172],\n",
      "        [1.7679],\n",
      "        [1.7825]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1669],\n",
      "        [1.3255],\n",
      "        [1.7807],\n",
      "        [1.7924]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1651],\n",
      "        [1.3319],\n",
      "        [1.7933],\n",
      "        [1.8012]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1635],\n",
      "        [1.3360],\n",
      "        [1.8054],\n",
      "        [1.8079]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [70/100], Loss: 0.0324\n",
      "tensor([[0.1623],\n",
      "        [1.3379],\n",
      "        [1.8163],\n",
      "        [1.8124]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1619],\n",
      "        [1.3377],\n",
      "        [1.8256],\n",
      "        [1.8143]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1623],\n",
      "        [1.3357],\n",
      "        [1.8329],\n",
      "        [1.8137]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1635],\n",
      "        [1.3321],\n",
      "        [1.8381],\n",
      "        [1.8106]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1654],\n",
      "        [1.3273],\n",
      "        [1.8411],\n",
      "        [1.8055]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1678],\n",
      "        [1.3221],\n",
      "        [1.8419],\n",
      "        [1.7992]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1705],\n",
      "        [1.3169],\n",
      "        [1.8407],\n",
      "        [1.7923]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1733],\n",
      "        [1.3121],\n",
      "        [1.8379],\n",
      "        [1.7853]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1760],\n",
      "        [1.3079],\n",
      "        [1.8340],\n",
      "        [1.7788]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1786],\n",
      "        [1.3044],\n",
      "        [1.8293],\n",
      "        [1.7732]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [80/100], Loss: 0.0305\n",
      "tensor([[0.1809],\n",
      "        [1.3017],\n",
      "        [1.8245],\n",
      "        [1.7685]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1830],\n",
      "        [1.2997],\n",
      "        [1.8197],\n",
      "        [1.7650]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1848],\n",
      "        [1.2984],\n",
      "        [1.8155],\n",
      "        [1.7626]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1864],\n",
      "        [1.2977],\n",
      "        [1.8118],\n",
      "        [1.7615]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1878],\n",
      "        [1.2978],\n",
      "        [1.8089],\n",
      "        [1.7617]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1891],\n",
      "        [1.2981],\n",
      "        [1.8069],\n",
      "        [1.7626]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1904],\n",
      "        [1.2985],\n",
      "        [1.8057],\n",
      "        [1.7639]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1916],\n",
      "        [1.2989],\n",
      "        [1.8051],\n",
      "        [1.7654]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1927],\n",
      "        [1.2992],\n",
      "        [1.8049],\n",
      "        [1.7668]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1936],\n",
      "        [1.2992],\n",
      "        [1.8051],\n",
      "        [1.7679]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [90/100], Loss: 0.0293\n",
      "tensor([[0.1941],\n",
      "        [1.2989],\n",
      "        [1.8053],\n",
      "        [1.7685]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1943],\n",
      "        [1.2982],\n",
      "        [1.8055],\n",
      "        [1.7685]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1940],\n",
      "        [1.2972],\n",
      "        [1.8056],\n",
      "        [1.7677]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1933],\n",
      "        [1.2960],\n",
      "        [1.8054],\n",
      "        [1.7663]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1922],\n",
      "        [1.2945],\n",
      "        [1.8050],\n",
      "        [1.7644]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1907],\n",
      "        [1.2930],\n",
      "        [1.8045],\n",
      "        [1.7622]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1888],\n",
      "        [1.2916],\n",
      "        [1.8040],\n",
      "        [1.7598]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1869],\n",
      "        [1.2904],\n",
      "        [1.8035],\n",
      "        [1.7575]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1849],\n",
      "        [1.2895],\n",
      "        [1.8031],\n",
      "        [1.7555]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "tensor([[0.1830],\n",
      "        [1.2891],\n",
      "        [1.8030],\n",
      "        [1.7540]], grad_fn=<SliceBackward0>) tensor([0.2000, 1.4000, 1.8000, 1.6000])\n",
      "Epoch [100/100], Loss: 0.0288\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "Test Accuracy: 0.0\n",
      "Prediction: tensor([[1.7436],\n",
      "        [3.8552],\n",
      "        [4.5802],\n",
      "        [4.8171],\n",
      "        [4.0543],\n",
      "        [4.8320],\n",
      "        [4.4015],\n",
      "        [6.1662],\n",
      "        [4.2080],\n",
      "        [1.7924],\n",
      "        [4.4881],\n",
      "        [4.6630],\n",
      "        [3.8853],\n",
      "        [1.8495],\n",
      "        [1.7398],\n",
      "        [1.6985],\n",
      "        [4.8530],\n",
      "        [4.5709],\n",
      "        [4.7706],\n",
      "        [3.0359],\n",
      "        [4.2900],\n",
      "        [1.8041],\n",
      "        [1.9222],\n",
      "        [1.8076],\n",
      "        [4.7961],\n",
      "        [3.7477],\n",
      "        [4.6274],\n",
      "        [4.5791],\n",
      "        [4.0599],\n",
      "        [4.2727],\n",
      "        [1.7821],\n",
      "        [3.3219],\n",
      "        [4.5532],\n",
      "        [4.0772],\n",
      "        [2.1137],\n",
      "        [1.8008],\n",
      "        [5.4516],\n",
      "        [4.7090],\n",
      "        [4.0634],\n",
      "        [4.2711],\n",
      "        [3.7753],\n",
      "        [5.2322],\n",
      "        [4.7481],\n",
      "        [1.9163],\n",
      "        [1.8768],\n",
      "        [4.3492],\n",
      "        [3.8771],\n",
      "        [4.3397],\n",
      "        [4.1021],\n",
      "        [1.9083],\n",
      "        [1.8569],\n",
      "        [5.3847],\n",
      "        [5.2591],\n",
      "        [4.0184],\n",
      "        [5.4312],\n",
      "        [5.1083],\n",
      "        [5.9903],\n",
      "        [4.4197],\n",
      "        [5.6977],\n",
      "        [1.8470],\n",
      "        [1.6926],\n",
      "        [4.0526],\n",
      "        [1.8076],\n",
      "        [4.2134],\n",
      "        [5.6185],\n",
      "        [1.9594],\n",
      "        [1.8509],\n",
      "        [1.7992],\n",
      "        [6.0315],\n",
      "        [4.3224],\n",
      "        [4.8478],\n",
      "        [1.7924],\n",
      "        [3.3930],\n",
      "        [4.9503],\n",
      "        [1.8473],\n",
      "        [3.9539],\n",
      "        [1.8591],\n",
      "        [5.4458],\n",
      "        [4.9296],\n",
      "        [5.2556],\n",
      "        [5.2101],\n",
      "        [3.9803],\n",
      "        [1.9659],\n",
      "        [1.5996],\n",
      "        [4.2944],\n",
      "        [3.5154],\n",
      "        [1.8631],\n",
      "        [3.8356],\n",
      "        [5.3282],\n",
      "        [1.8194],\n",
      "        [5.7193],\n",
      "        [5.2541],\n",
      "        [1.7393],\n",
      "        [3.9319],\n",
      "        [4.3510],\n",
      "        [4.4349],\n",
      "        [4.2579],\n",
      "        [3.6970],\n",
      "        [1.9001],\n",
      "        [1.8591],\n",
      "        [5.2101],\n",
      "        [4.6723],\n",
      "        [1.9028],\n",
      "        [1.8017],\n",
      "        [1.8627],\n",
      "        [4.0502],\n",
      "        [3.7901],\n",
      "        [1.7906],\n",
      "        [5.2291],\n",
      "        [5.4914],\n",
      "        [5.0880],\n",
      "        [1.7555],\n",
      "        [5.3692],\n",
      "        [5.1687],\n",
      "        [1.7970],\n",
      "        [1.8022],\n",
      "        [5.2691],\n",
      "        [4.4542],\n",
      "        [1.6301],\n",
      "        [4.7044],\n",
      "        [3.3440],\n",
      "        [1.9021],\n",
      "        [4.0168],\n",
      "        [1.8485],\n",
      "        [4.8530],\n",
      "        [4.8571],\n",
      "        [5.1304],\n",
      "        [5.5602],\n",
      "        [4.9486],\n",
      "        [1.9626],\n",
      "        [1.7517],\n",
      "        [1.8118],\n",
      "        [4.3857],\n",
      "        [2.1273],\n",
      "        [4.5091],\n",
      "        [5.9243],\n",
      "        [3.6048],\n",
      "        [1.9691],\n",
      "        [4.7675],\n",
      "        [3.7833],\n",
      "        [1.7415],\n",
      "        [1.8780],\n",
      "        [4.2573],\n",
      "        [5.0545],\n",
      "        [1.8510],\n",
      "        [1.8990],\n",
      "        [4.6119],\n",
      "        [3.4938],\n",
      "        [5.2691],\n",
      "        [4.4390]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the Iris dataset from CSV\n",
    "iris_df = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {\"Setosa\": 0, \"Versicolor\": 1, \"Virginica\": 2}\n",
    "iris_df[\"variety\"] = iris_df[\"variety\"].map(label_mapping)\n",
    "\n",
    "# Shuffle the dataset\n",
    "iris_df = iris_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split features and target\n",
    "X = iris_df.drop(columns=[\"variety\", \"petal.width\"]).values\n",
    "y = iris_df[\"petal.width\"].values\n",
    "\n",
    "# Normalize features\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train_tensor, X_test_tensor = X_tensor[:train_size], X_tensor[train_size:]\n",
    "y_train_tensor, y_test_tensor = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "\n",
    "# Define the neural network model using PyTorch\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 25)\n",
    "        self.fc2 = nn.Linear(25, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    print(outputs[:4], y_train_tensor[:4])\n",
    "    loss = criterion(outputs.squeeze(), y_train_tensor)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print(\"Predictions:\", predicted)\n",
    "    accuracy = (predicted == y_test_tensor).float().mean()\n",
    "    print(\"Test Accuracy:\", accuracy.item())\n",
    "\n",
    "    outputs = model(\n",
    "        torch.tensor(\n",
    "            iris_df.drop(columns=[\"petal.width\", \"variety\"]).values,\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "    )\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print(\"Prediction:\", outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
