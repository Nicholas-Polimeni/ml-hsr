{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Geoname ID         Name  Population Country name EN  Latitude  Longitude\n",
      "0     2549076    Ezzhiliga        4211         Morocco  33.30000   -6.53000\n",
      "1     2550985      Driouch       16096         Morocco  34.97705   -3.37902\n",
      "2     2552615  Dar Bouazza      165295         Morocco  33.51535   -7.81677\n",
      "3     2552886   Dar Chaoui        1401         Morocco  35.53770   -5.71742\n",
      "4     2555157      Bouarfa       31499         Morocco  32.53379   -1.96209\n",
      "                                           path  viability         city_2  \\\n",
      "0  [[-84.38798, 33.749], [-99.12766, 19.42847]]   0.452561    Mexico City   \n",
      "1  [[-84.38798, 33.749], [-74.00597, 40.71427]]   0.348961  New York City   \n",
      "2  [[-84.38798, 33.749], [121.45806, 31.22222]]   0.344624       Shanghai   \n",
      "3   [[-84.38798, 33.749], [116.39723, 39.9075]]   0.235516        Beijing   \n",
      "4     [[-84.38798, 33.749], [3.39467, 6.45407]]   0.193363          Lagos   \n",
      "\n",
      "     color  \n",
      "0  #ff0000  \n",
      "1  #df7000  \n",
      "2  #bfbf00  \n",
      "3  #50a000  \n",
      "4  #008000  \n"
     ]
    }
   ],
   "source": [
    "from colour import Color\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydeck as pdk\n",
    "\n",
    "\n",
    "def get_dataset(csv_name):\n",
    "    dataset = pd.read_csv(csv_name, delimiter=\";\")\n",
    "    dataset = dataset.drop_duplicates()\n",
    "\n",
    "    # pick columns to use\n",
    "    dataset[\"Latitude\"] = dataset[\"Coordinates\"].str.split(\",\").str[0].astype(float)\n",
    "    dataset[\"Longitude\"] = dataset[\"Coordinates\"].str.split(\",\").str[1].astype(float)\n",
    "    columns = [\n",
    "        \"Geoname ID\",\n",
    "        \"Name\",\n",
    "        \"Population\",\n",
    "        \"Country name EN\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "    ]\n",
    "    dataset = dataset[columns]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dist(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of the earth in km\n",
    "    dLat = np.deg2rad(lat2 - lat1)\n",
    "    dLon = np.deg2rad(lon2 - lon1)\n",
    "    a = np.sin(dLat / 2) * np.sin(dLat / 2) + np.cos(np.deg2rad(lat1)) * np.cos(\n",
    "        np.deg2rad(lat2)\n",
    "    ) * np.sin(dLon / 2) * np.sin(dLon / 2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    d = R * c  # Distance in km\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_max_dist(dataset_item, dataset):\n",
    "    lat1 = dataset_item[\"Latitude\"]\n",
    "    lon1 = dataset_item[\"Longitude\"]\n",
    "    city_max_dist = 0\n",
    "    for _, row in dataset.iterrows():\n",
    "        lat2 = row[\"Latitude\"]\n",
    "        lon2 = row[\"Longitude\"]\n",
    "        dist = get_dist(lat1, lon1, lat2, lon2)\n",
    "        if dist > city_max_dist:\n",
    "            city_max_dist = dist\n",
    "    return city_max_dist\n",
    "\n",
    "\n",
    "def get_city_item(name_or_id, dataset):\n",
    "    def get_city_with_max_pop(subset):\n",
    "        return subset[subset[\"Population\"] == subset[\"Population\"].max()].iloc[0]\n",
    "\n",
    "    if isinstance(name_or_id, int):\n",
    "        subset = dataset[dataset[\"Geoname ID\"] == name_or_id]\n",
    "    else:\n",
    "        subset = dataset[dataset[\"Name\"].str.contains(name_or_id) == True]\n",
    "    return get_city_with_max_pop(subset)\n",
    "\n",
    "\n",
    "def get_viability(city_1, city_2, dataset, dataset_statistics, A=1, B=1, verbose=False):\n",
    "    min_pop, max_pop, avg_pop, min_dist, max_dist = (\n",
    "        dataset_statistics[\"min_pop\"],\n",
    "        dataset_statistics[\"max_pop\"],\n",
    "        dataset_statistics[\"avg_pop\"],\n",
    "        dataset_statistics[\"min_dist\"],\n",
    "        dataset_statistics[\"max_dist\"],\n",
    "    )\n",
    "    pop_1 = city_1[\"Population\"]\n",
    "    pop_2 = city_2[\"Population\"]\n",
    "    sum_pop = pop_1 + pop_2\n",
    "    dist = get_dist(\n",
    "        city_1[\"Latitude\"], city_1[\"Longitude\"], city_2[\"Latitude\"], city_2[\"Longitude\"]\n",
    "    )\n",
    "    normalized_pop = (sum_pop - min_pop) / (max_pop + avg_pop - min_pop)\n",
    "    normalized_dist = (dist - min_dist) / (max_dist - min_dist)\n",
    "    if verbose:\n",
    "        print(sum_pop, normalized_pop, dist, normalized_dist)\n",
    "    return A * normalized_pop - B * normalized_dist\n",
    "\n",
    "\n",
    "def find_most_viable_city(city_name, dataset):\n",
    "    city = get_city_item(city_name, dataset)\n",
    "    max_viability = 0\n",
    "    max_viable_city = None\n",
    "    for _, row in dataset.iterrows():\n",
    "        if row[\"Geoname ID\"] != city[\"Geoname ID\"]:\n",
    "            viability = get_viability(city, row, dataset)\n",
    "            if viability > max_viability:\n",
    "                max_viability = viability\n",
    "                max_viable_city = row\n",
    "    return max_viable_city\n",
    "\n",
    "\n",
    "def find_top_viable_cities(city_name, dataset, dataset_statistics, top_n=5):\n",
    "    city = get_city_item(city_name, dataset)\n",
    "    viabilities = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        if row[\"Geoname ID\"] != city[\"Geoname ID\"]:\n",
    "            viability = get_viability(city, row, dataset, dataset_statistics)\n",
    "            viabilities.append((viability, row))\n",
    "    viabilities.sort(key=lambda x: x[0], reverse=True)\n",
    "    return viabilities[:top_n]\n",
    "\n",
    "\n",
    "def get_viable_cities_paths(city_1_name, dataset, dataset_statistics, top_n=5):\n",
    "    city_1 = get_city_item(city_1_name, dataset)\n",
    "    most_viable_cities = find_top_viable_cities(\n",
    "        city_1_name, dataset, dataset_statistics, top_n\n",
    "    )\n",
    "    paths_dict = []\n",
    "    for city in most_viable_cities:\n",
    "        city_2 = city[1]\n",
    "        paths_dict.append(\n",
    "            {\n",
    "                \"path\": [\n",
    "                    [city_1[\"Longitude\"], city_1[\"Latitude\"]],\n",
    "                    [city_2[\"Longitude\"], city_2[\"Latitude\"]],\n",
    "                ],\n",
    "                \"viability\": city[0],\n",
    "                \"city_2\": city_2[\"Name\"],\n",
    "            }\n",
    "        )\n",
    "    red = Color(\"red\")\n",
    "    colors = list(red.range_to(Color(\"green\"), len(paths_dict)))\n",
    "    for i, path in enumerate(paths_dict):\n",
    "        path[\"color\"] = colors[i].hex_l\n",
    "    return pd.DataFrame(paths_dict)\n",
    "\n",
    "\n",
    "# mvc = find_most_viable_city(\"Atlanta\", dataset)\n",
    "\n",
    "# find_top_viable_cities(\"Atlanta\", dataset, 5)\n",
    "\n",
    "dataset = get_dataset(\"geonames.csv\")\n",
    "print(dataset.head())\n",
    "dataset_statistics = {\n",
    "    \"min_pop\": dataset[\"Population\"].min(),\n",
    "    \"max_pop\": dataset[\"Population\"].max(),\n",
    "    \"avg_pop\": dataset[\"Population\"].mean(),\n",
    "    \"min_dist\": 0,\n",
    "    \"max_dist\": get_max_dist(get_city_item(\"Atlanta\", dataset), dataset),\n",
    "}\n",
    "\n",
    "df1 = get_viable_cities_paths(\"Atlanta\", dataset, dataset_statistics, 5)\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "print(eval(df1[\"path\"][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
